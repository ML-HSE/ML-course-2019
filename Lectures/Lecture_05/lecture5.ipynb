{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Лекция №5. Введение в Natural Language Processing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Примеры использования NLP:**\n",
    "\n",
    "● Machine Translation\\\n",
    "Between different languages\\\n",
    "● Language modeling\\\n",
    "Model which can predict probability of sentence, or word, given context \\\n",
    "● Part of speech tagging\\\n",
    "Determine part of speech for each word\\\n",
    "● Parsing\\\n",
    "Determine parse tree for sentence which shows relations between words\\\n",
    "Natural language generation\\\n",
    "Convert some information (images, digits) into human readable way\\\n",
    "● Named entity recognition\\\n",
    "Determine which items in text map to proper classes. For example, people or\\\n",
    "organizations\\\n",
    "● Question answering\\\n",
    "Given a human language question, determine its answer\\\n",
    "● Topic modeling\\\n",
    "● Extract topics and determine which relate to text\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* **Сервис, позволяющий создавать чат-ботов:**\n",
    "<img src=\"Imgs/df.png\"> \n",
    "\n",
    "* **Siri:**\n",
    "<img src=\"Imgs/siri.jpeg\"> \n",
    "\n",
    "* **Виртуальная голосовая помощница с элементами искусственного интеллекта от Microsoft:**\n",
    "<img src=\"Imgs/cortana.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Библиотека NLTK - пакет библиотек и программ для символьной и статистической обработки естественного языка\n",
    "\n",
    "https://www.nltk.org/py-modindex.html\n",
    "\n",
    "\n",
    "## Библиотека Spacy - Python библиотека для обработки текстов. Работает быстрее чем NLTK, но поддерживает только английский\n",
    "https://spacy.io/\n",
    "\n",
    "**Spacy Features:**\n",
    "* Non-destructive tokenization\n",
    "* Named entity recognition\n",
    "* Support for 53+ languages\n",
    "* 23 statistical models for 11 languages\n",
    "* pretrained word vectors\n",
    "* State-of-the-art speed\n",
    "* Easy deep learning integration\n",
    "* Part-of-speech tagging\n",
    "* Labelled dependency parsing\n",
    "* Syntax-driven sentence segmentation\n",
    "* Built in visualizers for syntax and NER\n",
    "* Convenient string-to-hash mapping\n",
    "* Export to numpy data arrays\n",
    "* Efficient binary serialization\n",
    "* Easy model packaging and deployment\n",
    "* Robust, rigorously evaluated accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Represent word as WordNet"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " <img src=\"Imgs/wordnet.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Descrete representation\n",
    "word = word\n",
    "\n",
    "**Problems:**\n",
    "* Missing new words\n",
    "* Subjective\n",
    "* Requires human labor to create and adapt\n",
    "* Hard to compute accurate word similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encoding representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imgs/ohe.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot problem\n",
    "If we search for \"Seetle hotel\" we want \"motel\" to be shown too. **BUT:**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imgs/example1.png\">"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word coocurance\n",
    "\n",
    "### \"You shall know the word by the company it keeps\" (J.R. Firth 1957)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams\n",
    "<img src=\"Imgs/ngram.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Sliding window\n",
    "<img src=\"Imgs/window.png\"> \n",
    "\n",
    "Assume we have a text corpus given as a sequence of words $\\{w_1,w_2,\\dots,w_n\\}$ where $n$ may be larger than $10^{12}$ and $w_i \\in \\mathcal{V}$ belongs to a vocabulary of words $\\mathcal{V}$. A word $c \\in \\mathcal{V}$ is called *a context* of word $w_i$ if they are found together in the text. More formally, given some measure $L$ of closeness between two words (typical choice is $L=2$), a word $c \\in \\mathcal{V}$ is called a context if $c \\in \\{w_{i-L}, \\dots, w_{i-1}, w_{i+1}, \\dots, w_{i+L} \\}$ Let $\\mathbf{w},\\mathbf{c}\\in\\mathbb{R}^d$ be the *word embeddings* of word $w$ and context $c$, respectively.\n",
    "\n",
    "\n",
    " $\\#(w,c)$ is the number of times the pair $(w,c)$ appears in $\\mathcal{D}$ and $\\mathbf{w}^\\top\\mathbf{c}$ is the scalar product of vectors $\\mathbf{w}$ and $\\mathbf{c}$. Two important quantities which we will also use further are the number of times the word $w$ and the context $c$ appear in $\\mathcal{D}$, which can be computed as\n",
    "\n",
    "$$\n",
    "\\#(w) = \\sum_{c\\in\\mathcal{V}} \\#(w,c), \\quad \\#(c) = \\sum_{w\\in\\mathcal{V}} \\#(w,c).\n",
    "$$\n",
    "\n",
    "<img src=\"Imgs/sliding_window.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Co-ocurance matrix\n",
    "<img src=\"Imgs/comatrix1.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imgs/comatrix2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Bag of words (BoW) representation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<img src=\"Imgs/bow.jpeg\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of words:**\n",
    "\n",
    "<img src=\"Imgs/bow1.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Bag of n-grams:**\n",
    "<img src=\"Imgs/bow2.png\"> "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After transforming the text into a \"bag of words\", we can calculate various measures to characterize the text. The most common type of characteristics, or features calculated from the Bag-of-words model is term frequency, namely, the number of times a term appears in the text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF\n",
    "A problem with scoring word frequency is that highly frequent words start to dominate in the document (e.g. larger score), but may not contain as much “informational content” to the model as rarer but perhaps domain specific words.\n",
    "\n",
    "One approach is to rescale the frequency of words by how often they appear in all documents, so that the scores for frequent words like “the” that are also frequent across all documents are penalized.\n",
    "\n",
    "This approach to scoring is called Term Frequency – Inverse Document Frequency, or TF-IDF for short, where:\n",
    "\n",
    "* **Term Frequency:** is a scoring of the frequency of the word in the current document.\n",
    "* **Inverse Document Frequency:** is a scoring of how rare the word is across documents.\n",
    "\n",
    "The scores are a weighting where not all words are equally as important or interesting.\n",
    "\n",
    "<img src=\"Imgs/tfidf1.png\"> \n",
    "<img src=\"Imgs/tfidf2.png\"> "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 195,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'John': 1, 'likes': 2, 'to': 1, 'watch': 1, 'movies': 2, 'Mary': 1, 'too': 1}\n"
     ]
    }
   ],
   "source": [
    "text = ' John likes to watch movies. Mary likes movies too. '\n",
    "\n",
    "BoW1 = {\"John\":1,\"likes\":2,\"to\":1,\"watch\":1,\"movies\":2,\"Mary\":1,\"too\":1};\n",
    "print(BoW1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 198,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['at', 'eight', \"o'clock\", 'on', 'thursday', 'morning', 'arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import re\n",
    "import numpy as np\n",
    "from nltk.tokenize import word_tokenize\n",
    "sentence = \"\"\"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence.lower())\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 199,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm') # English multi-task CNN trained on OntoNotes. Assigns context-specific token vectors, POS tags, dependency parse and named entities."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', ',', 'don', '’', 't', 'slap', 'the', 'green', 'witch']\n"
     ]
    }
   ],
   "source": [
    "from nltk.tokenize import TweetTokenizer\n",
    "tokenizer = TweetTokenizer()\n",
    "print(tokenizer.tokenize(text.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 200,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['mary', ',', 'do', 'n’t', 'slap', 'the', 'green', 'witch']\n"
     ]
    }
   ],
   "source": [
    "text = \"Mary, don’t slap the green witch\"\n",
    "print([str(token) for token in nlp(text.lower())])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['snow', 'white', 'and', 'the', 'seven', 'degrees', '#makeamoviecold', '@midnight', ':)']\n"
     ]
    }
   ],
   "source": [
    "tweet=u\"Snow White and the Seven Degrees #MakeAMovieCold@midnight:)\"\n",
    "print(tokenizer.tokenize(tweet.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['this', 'is', 'a', 'cooool', '#dummysmiley', ':', ':-)', ':-p', '<3', 'and', 'some', 'arrows', '<', '>', '->', '<--']\n"
     ]
    }
   ],
   "source": [
    "s0 = \"This is a cooool #dummysmiley: :-) :-P <3 and some arrows < > -> <--\"\n",
    "print(tokenizer.tokenize(s0.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[':', 'this', 'is', 'waaayyy', 'too', 'much', 'for', 'you', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "s1 = '@remy: This is waaaaayyyy too much for you!!!!!!'\n",
    "tokenizer = TweetTokenizer(strip_handles=True, reduce_len=True)\n",
    "print(tokenizer.tokenize(s1.lower()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['@', 'remy', ':', 'This', 'is', 'waaaaayyyy', 'too', 'much', 'for', 'you', '!', '!', '!', '!', '!', '!']\n"
     ]
    }
   ],
   "source": [
    "print(nltk.word_tokenize(s1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## N-grams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 207,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['At', 'eight', \"o'clock\"], ['eight', \"o'clock\", 'on'], [\"o'clock\", 'on', 'Thursday'], ['on', 'Thursday', 'morning'], ['Thursday', 'morning', 'Arthur'], ['morning', 'Arthur', \"didn't\"], ['Arthur', \"didn't\", 'feel'], [\"didn't\", 'feel', 'very'], ['feel', 'very', 'good'], ['very', 'good', '.']]\n"
     ]
    }
   ],
   "source": [
    "#Func to create n-grams\n",
    "def n_grams(text, n):\n",
    "    '''\n",
    "    takes tokens or text, returns a list of ngrams\n",
    "    '''\n",
    "    return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "text = \"At eight o'clock on Thursday morning Arthur didn't feel very good.\"\n",
    "text = tokenizer.tokenize(text)\n",
    "print(n_grams(text, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[['Methanol', 'is', 'tasty']]\n"
     ]
    }
   ],
   "source": [
    "def n_grams(text, n):\n",
    "    '''\n",
    "    takes tokens or text, returns a list of ngrams\n",
    "    '''\n",
    "    return [text[i:i+n] for i in range(len(text) - n + 1)]\n",
    "\n",
    "cleaned = \"Methanol is tasty\"\n",
    "cleaned = tokenizer.tokenize(cleaned)\n",
    "print(n_grams(cleaned, 3))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### using nltk lib"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.util import ngrams"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {},
   "outputs": [],
   "source": [
    "#define a function for extracting n-grams\n",
    "def extract_ngrams(data, num):\n",
    "    n_grams = ngrams(nltk.word_tokenize(data), num)\n",
    "    return [ ' '.join(grams) for grams in n_grams]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1-gram:  ['A class is', 'class is a', 'is a blueprint', 'a blueprint for', 'blueprint for the', 'for the object', 'the object .']\n"
     ]
    }
   ],
   "source": [
    "data = 'A class is a blueprint for the object.'\n",
    " \n",
    "print(\"1-gram: \", extract_ngrams(data, 3)) #exstarct 2,3 grams"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## One-hot encode a sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['At', 'eight', 'eight', \"o'clock\", 'on', 'Thursday', 'Thursday', 'morning', 'Arthur', 'did', \"n't\", 'feel', 'very', 'good', '.']\n"
     ]
    }
   ],
   "source": [
    "sentence = \"\"\"At eight eight o'clock on Thursday Thursday morning Arthur didn't feel very good.\"\"\"\n",
    "tokens = nltk.word_tokenize(sentence)\n",
    "print(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "s = pd.Series(tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>.</th>\n",
       "      <th>Arthur</th>\n",
       "      <th>At</th>\n",
       "      <th>Thursday</th>\n",
       "      <th>did</th>\n",
       "      <th>eight</th>\n",
       "      <th>feel</th>\n",
       "      <th>good</th>\n",
       "      <th>morning</th>\n",
       "      <th>n't</th>\n",
       "      <th>o'clock</th>\n",
       "      <th>on</th>\n",
       "      <th>very</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>5</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>6</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>8</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>9</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>10</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>11</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>12</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>13</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>14</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    .  Arthur  At  Thursday  did  eight  feel  good  morning  n't  o'clock  \\\n",
       "0   0       0   1         0    0      0     0     0        0    0        0   \n",
       "1   0       0   0         0    0      1     0     0        0    0        0   \n",
       "2   0       0   0         0    0      1     0     0        0    0        0   \n",
       "3   0       0   0         0    0      0     0     0        0    0        1   \n",
       "4   0       0   0         0    0      0     0     0        0    0        0   \n",
       "5   0       0   0         1    0      0     0     0        0    0        0   \n",
       "6   0       0   0         1    0      0     0     0        0    0        0   \n",
       "7   0       0   0         0    0      0     0     0        1    0        0   \n",
       "8   0       1   0         0    0      0     0     0        0    0        0   \n",
       "9   0       0   0         0    1      0     0     0        0    0        0   \n",
       "10  0       0   0         0    0      0     0     0        0    1        0   \n",
       "11  0       0   0         0    0      0     1     0        0    0        0   \n",
       "12  0       0   0         0    0      0     0     0        0    0        0   \n",
       "13  0       0   0         0    0      0     0     1        0    0        0   \n",
       "14  1       0   0         0    0      0     0     0        0    0        0   \n",
       "\n",
       "    on  very  \n",
       "0    0     0  \n",
       "1    0     0  \n",
       "2    0     0  \n",
       "3    0     0  \n",
       "4    1     0  \n",
       "5    0     0  \n",
       "6    0     0  \n",
       "7    0     0  \n",
       "8    0     0  \n",
       "9    0     0  \n",
       "10   0     0  \n",
       "11   0     0  \n",
       "12   0     1  \n",
       "13   0     0  \n",
       "14   0     0  "
      ]
     },
     "execution_count": 220,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.get_dummies(s)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Co-ocurance matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 169,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk import bigrams\n",
    "import itertools\n",
    "\n",
    "\n",
    "def generate_co_occurrence_matrix(corpus):\n",
    "    vocab = set(corpus)\n",
    "    vocab = list(vocab)\n",
    "    vocab_index = {word: i for i, word in enumerate(vocab)}\n",
    "\n",
    "    # Create bigrams from all words in corpus\n",
    "    bi_grams = list(bigrams(corpus))\n",
    "\n",
    "    # Frequency distribution of bigrams ((word1, word2), num_occurrences)\n",
    "    bigram_freq = nltk.FreqDist(bi_grams).most_common(len(bi_grams))\n",
    "\n",
    "    # Initialise co-occurrence matrix\n",
    "    # co_occurrence_matrix[current][previous]\n",
    "    co_occurrence_matrix = np.zeros((len(vocab), len(vocab)))\n",
    "\n",
    "    # Loop through the bigrams taking the current and previous word,\n",
    "    # and the number of occurrences of the bigram.\n",
    "    for bigram in bigram_freq:\n",
    "        current = bigram[0][1]\n",
    "        previous = bigram[0][0]\n",
    "        count = bigram[1]\n",
    "        pos_current = vocab_index[current]\n",
    "        pos_previous = vocab_index[previous]\n",
    "        co_occurrence_matrix[pos_current][pos_previous] = count\n",
    "    co_occurrence_matrix = np.matrix(co_occurrence_matrix)\n",
    "\n",
    "    # return the matrix and the index\n",
    "    return co_occurrence_matrix, vocab_index\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Where', 'Python', 'is', 'used', 'What', 'is', 'Python', 'used', 'in', 'Why', 'Python', 'is', 'best', 'What', 'companies', 'use', 'Python']\n"
     ]
    }
   ],
   "source": [
    "text_data = [['Where', 'Python', 'is', 'used'],\n",
    "             ['What', 'is', 'Python', 'used', 'in'],\n",
    "             ['Why', 'Python', 'is', 'best'],\n",
    "             ['What', 'companies', 'use', 'Python']]\n",
    "\n",
    "# Create one list using many lists\n",
    "data = list(itertools.chain.from_iterable(text_data))\n",
    "print(data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Python</th>\n",
       "      <th>Where</th>\n",
       "      <th>Why</th>\n",
       "      <th>best</th>\n",
       "      <th>in</th>\n",
       "      <th>companies</th>\n",
       "      <th>use</th>\n",
       "      <th>is</th>\n",
       "      <th>What</th>\n",
       "      <th>used</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>Python</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Where</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>Why</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>best</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>in</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>companies</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>use</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>is</td>\n",
       "      <td>2.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>What</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>used</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Python  Where  Why  best   in  companies  use   is  What  used\n",
       "Python        0.0    1.0  1.0   0.0  0.0        0.0  1.0  1.0   0.0   0.0\n",
       "Where         0.0    0.0  0.0   0.0  0.0        0.0  0.0  0.0   0.0   0.0\n",
       "Why           0.0    0.0  0.0   0.0  1.0        0.0  0.0  0.0   0.0   0.0\n",
       "best          0.0    0.0  0.0   0.0  0.0        0.0  0.0  1.0   0.0   0.0\n",
       "in            0.0    0.0  0.0   0.0  0.0        0.0  0.0  0.0   0.0   1.0\n",
       "companies     0.0    0.0  0.0   0.0  0.0        0.0  0.0  0.0   1.0   0.0\n",
       "use           0.0    0.0  0.0   0.0  0.0        1.0  0.0  0.0   0.0   0.0\n",
       "is            2.0    0.0  0.0   0.0  0.0        0.0  0.0  0.0   1.0   0.0\n",
       "What          0.0    0.0  0.0   1.0  0.0        0.0  0.0  0.0   0.0   1.0\n",
       "used          1.0    0.0  0.0   0.0  0.0        0.0  0.0  1.0   0.0   0.0"
      ]
     },
     "execution_count": 222,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix, vocab_index = generate_co_occurrence_matrix(data)\n",
    "\n",
    "data_matrix = pd.DataFrame(matrix, index=vocab_index,\n",
    "                             columns=vocab_index)\n",
    "data_matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bag-of-Words implementation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.\n"
     ]
    }
   ],
   "source": [
    "text = \"\"\"Beans. I was trying to explain to somebody as we were flying in, that’s corn. That’s beans. And they were very impressed at my agricultural knowledge. Please give it up for Amaury once again for that outstanding introduction. I have a bunch of good friends here today, including somebody who I served with, who is one of the finest senators in the country, and we’re lucky to have him, your Senator, Dick Durbin is here. I also noticed, by the way, former Governor Edgar here, who I haven’t seen in a long time, and somehow he has not aged and I have. And it’s great to see you, Governor. I want to thank President Killeen and everybody at the U of I System for making it possible for me to be here today. And I am deeply honored at the Paul Douglas Award that is being given to me. He is somebody who set the path for so much outstanding public service here in Illinois. Now, I want to start by addressing the elephant in the room. I know people are still wondering why I didn’t speak at the commencement.\"\"\"\n",
    "print(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['beans ',\n",
       " 'i was trying to explain to somebody as we were flying in that s corn ',\n",
       " 'that s beans ',\n",
       " 'and they were very impressed at my agricultural knowledge ',\n",
       " 'please give it up for amaury once again for that outstanding introduction ',\n",
       " 'i have a bunch of good friends here today including somebody who i served with who is one of the finest senators in the country and we re lucky to have him your senator dick durbin is here ',\n",
       " 'i also noticed by the way former governor edgar here who i haven t seen in a long time and somehow he has not aged and i have ',\n",
       " 'and it s great to see you governor ',\n",
       " 'i want to thank president killeen and everybody at the u of i system for making it possible for me to be here today ',\n",
       " 'and i am deeply honored at the paul douglas award that is being given to me ',\n",
       " 'he is somebody who set the path for so much outstanding public service here in illinois ',\n",
       " 'now i want to start by addressing the elephant in the room ',\n",
       " 'i know people are still wondering why i didn t speak at the commencement ']"
      ]
     },
     "execution_count": 129,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = nltk.sent_tokenize(text) \n",
    "for i in range(len(dataset)): \n",
    "    dataset[i] = dataset[i].lower() \n",
    "    dataset[i] = re.sub(r'\\W', ' ', dataset[i]) \n",
    "    dataset[i] = re.sub(r'\\s+', ' ', dataset[i]) \n",
    "dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'beans': 2,\n",
       " 'i': 12,\n",
       " 'was': 1,\n",
       " 'trying': 1,\n",
       " 'to': 8,\n",
       " 'explain': 1,\n",
       " 'somebody': 3,\n",
       " 'as': 1,\n",
       " 'we': 2,\n",
       " 'were': 2,\n",
       " 'flying': 1,\n",
       " 'in': 5,\n",
       " 'that': 4,\n",
       " 's': 3,\n",
       " 'corn': 1,\n",
       " 'and': 7,\n",
       " 'they': 1,\n",
       " 'very': 1,\n",
       " 'impressed': 1,\n",
       " 'at': 4,\n",
       " 'my': 1,\n",
       " 'agricultural': 1,\n",
       " 'knowledge': 1,\n",
       " 'please': 1,\n",
       " 'give': 1,\n",
       " 'it': 3,\n",
       " 'up': 1,\n",
       " 'for': 5,\n",
       " 'amaury': 1,\n",
       " 'once': 1,\n",
       " 'again': 1,\n",
       " 'outstanding': 2,\n",
       " 'introduction': 1,\n",
       " 'have': 3,\n",
       " 'a': 2,\n",
       " 'bunch': 1,\n",
       " 'of': 3,\n",
       " 'good': 1,\n",
       " 'friends': 1,\n",
       " 'here': 5,\n",
       " 'today': 2,\n",
       " 'including': 1,\n",
       " 'who': 4,\n",
       " 'served': 1,\n",
       " 'with': 1,\n",
       " 'is': 4,\n",
       " 'one': 1,\n",
       " 'the': 9,\n",
       " 'finest': 1,\n",
       " 'senators': 1,\n",
       " 'country': 1,\n",
       " 're': 1,\n",
       " 'lucky': 1,\n",
       " 'him': 1,\n",
       " 'your': 1,\n",
       " 'senator': 1,\n",
       " 'dick': 1,\n",
       " 'durbin': 1,\n",
       " 'also': 1,\n",
       " 'noticed': 1,\n",
       " 'by': 2,\n",
       " 'way': 1,\n",
       " 'former': 1,\n",
       " 'governor': 2,\n",
       " 'edgar': 1,\n",
       " 'haven': 1,\n",
       " 't': 2,\n",
       " 'seen': 1,\n",
       " 'long': 1,\n",
       " 'time': 1,\n",
       " 'somehow': 1,\n",
       " 'he': 2,\n",
       " 'has': 1,\n",
       " 'not': 1,\n",
       " 'aged': 1,\n",
       " 'great': 1,\n",
       " 'see': 1,\n",
       " 'you': 1,\n",
       " 'want': 2,\n",
       " 'thank': 1,\n",
       " 'president': 1,\n",
       " 'killeen': 1,\n",
       " 'everybody': 1,\n",
       " 'u': 1,\n",
       " 'system': 1,\n",
       " 'making': 1,\n",
       " 'possible': 1,\n",
       " 'me': 2,\n",
       " 'be': 1,\n",
       " 'am': 1,\n",
       " 'deeply': 1,\n",
       " 'honored': 1,\n",
       " 'paul': 1,\n",
       " 'douglas': 1,\n",
       " 'award': 1,\n",
       " 'being': 1,\n",
       " 'given': 1,\n",
       " 'set': 1,\n",
       " 'path': 1,\n",
       " 'so': 1,\n",
       " 'much': 1,\n",
       " 'public': 1,\n",
       " 'service': 1,\n",
       " 'illinois': 1,\n",
       " 'now': 1,\n",
       " 'start': 1,\n",
       " 'addressing': 1,\n",
       " 'elephant': 1,\n",
       " 'room': 1,\n",
       " 'know': 1,\n",
       " 'people': 1,\n",
       " 'are': 1,\n",
       " 'still': 1,\n",
       " 'wondering': 1,\n",
       " 'why': 1,\n",
       " 'didn': 1,\n",
       " 'speak': 1,\n",
       " 'commencement': 1}"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Creating the Bag of Words model \n",
    "word2count = {} \n",
    "for data in dataset: \n",
    "    words = nltk.word_tokenize(data) \n",
    "    for word in words: \n",
    "        if word not in word2count.keys(): \n",
    "            word2count[word] = 1\n",
    "        else: \n",
    "            word2count[word] += 1\n",
    "word2count"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "118"
      ]
     },
     "execution_count": 224,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(word2count)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "metadata": {},
   "outputs": [],
   "source": [
    "#check how many words are in the vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i', 'the', 'to', 'and', 'in', 'for', 'here', 'that', 'at', 'who']"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import heapq \n",
    "freq_words = heapq.nlargest(10, word2count, key=word2count.get)\n",
    "freq_words\n",
    "#change n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Step #3 : Building the Bag of Words model**\n",
    "\n",
    "In this step we construct a vector, which would tell us whether a word in each sentence is a frequent word or not. \\\n",
    "If a word in a sentence is a frequent word, we set it as 1, else we set it as 0. \\\n",
    "This can be implemented with the help of following code:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 0, 1, 0, 1, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 0, 0, 0, 0, 1, 0, 0],\n",
       "       [0, 0, 0, 1, 0, 0, 0, 0, 1, 0],\n",
       "       [0, 0, 0, 0, 0, 1, 0, 1, 0, 0],\n",
       "       [1, 1, 1, 1, 1, 0, 1, 0, 0, 1],\n",
       "       [1, 1, 0, 1, 1, 0, 1, 0, 0, 1],\n",
       "       [0, 0, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 1, 1, 0, 1, 1, 0, 1, 0],\n",
       "       [1, 1, 1, 1, 0, 0, 0, 1, 1, 0],\n",
       "       [0, 1, 0, 0, 1, 1, 1, 0, 0, 1],\n",
       "       [1, 1, 1, 0, 1, 0, 0, 0, 0, 0],\n",
       "       [1, 1, 0, 0, 0, 0, 0, 0, 1, 0]])"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X = [] \n",
    "for data in dataset: \n",
    "    vector = [] \n",
    "    for word in freq_words: \n",
    "        if word in nltk.word_tokenize(data): \n",
    "            vector.append(1) \n",
    "        else: \n",
    "            vector.append(0) \n",
    "    X.append(vector) \n",
    "X = np.asarray(X) \n",
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a29acb810>"
      ]
     },
     "execution_count": 229,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAW4AAAD9CAYAAACcJ53WAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4xLjEsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy8QZhcZAAAbp0lEQVR4nO2df7RdZXnnP88NSYyAoSALTcCJWo3oUHG42NJaG+SHiFLSQRorQaXU6MIRaKcqU5lBFkWhCl1QlqWRCkIFC7gWgiLS0YmgogRrDEn4JT8Gg+AaVGRQRsLNM3/snZyTyz1nJ+ees8933/P9rHVWzj37nLs/ed73PHffvc99v5GZGGOMaQ5jwxYwxhizY7hxG2NMw3DjNsaYhuHGbYwxDcON2xhjGoYbtzHGNAz1xn0EcA/wI+C0EfdQcFDxUHBQ8VBwUPFQcKjHIzNVb7My8/7MfFlmzsnMH2bmq0fUQ8FBxUPBQcVDwUHFQ8GhNo/KI+6IeFVEfCQiLoyIC8r7+w7kp8i2vJ7iJ9YDwDPAF4Cja9ivooeCg4qHgoOKh4KDioeCQ20eXRt3RHyk3HEAtwOry/tXRcSgfxVZCPy47euN5WN1o+Ch4KDioeCg4qHgoOKh4FCbR2R2/pP3iLgXeE1mbpr0+BxgfWa+osPrVgArAGLW/APGxnbeYbFjjnkbhx/2R7zv/R8C4LjjjuHA8f059S//+w5/r+mg4KHgoOKh4KDioeCg4qHg0G+PZ595JDptqzpVshlYMMXjLy63TUlmrszM8cwc76VpAzyy8VH22bu1670XvphHH/1pT99rOih4KDioeCg4qHgoOKh4KDjU6VHVuE8Fvh4RX42IleXtJuDrwCl9t2lj9R1r+O3ffimLFu3D7Nmz+dM/PZobvnzzIHcp66HgoOKh4KDioeCg4qHgUKfHTt02ZuZNEfFKihPuCynOb28EVmfmRN9t2piYmOCUU0/nxq9cyayxMS773L+yYcO9g9ylrIeCg4qHgoOKh4KDioeCQ50eXc9x94Od5iz0urHGGLODTOcctzHGGDHcuI0xpmG4cRtjTMNw4zbGmIbR9VMl/eDpn9w66F1UMm/BHw5bAXAt2nEttFAYD/CYbC8+4jbGmIbhxm2MMQ3DjdsYYxqGG7cxxjQM6cZ9+sfP541vfQdLl79/qB5vPnwJ69fdwt0bvsWHP/SBoTi4Fi1cCy0Hj0f9HtKNe+mRh3Hx+X87VIexsTEuvOBs3nbUcvZ77cEsW7aUffedcjXbgeJatHAtdBzA4zEMD+nGPb7/fsx/wa5DdXj9ga/j/vsf4sEHH2bTpk1cffWX+OOj3ly7h2vRwrXQcQCPxzA8pBu3AgsWvogfb/zJ1q83PvIoCxa8aIhGw8O1aKFQCwUHFVRqUZdHz407Ik7osm1FRNwREXdccvlVve5CgojnLtA16BUVVXEtWijUQsFBBZVa1OUxnb+cPBO4dKoNmbkSWAmw6fEHGj2TVJI1FHAtWijUQsFBBZVaSCTgRMTaDrc7gb36biOISrKGAq5FC4VaKDiooFILiQQciub8ZuAXkx4P4Dt9t5nEh844h9U/WMsTTzzJIUuXc9KJx3NMzRccVJI1XIsWroWOA3g8huFRlfL+z8ClmfmtKbZdmZnvrNqBwqkSlYVrFBbycS1aqNRCAYXxAI9JO90ScKoyJ0/ssq2yaRtjjOk//jigMcY0DDduY4xpGG7cxhjTMLpenOwHO81ZOPSLk8aY7vjipB7dLk76iNsYYxqGG7cxxjQMN25jjGkYbtzGGNMwpBv3KCVaNMFBxUPBQcVDwcEJOPV7yH6qZGxsjLvW38oRR/4ZGzc+yndvu5Hlx5/EXXfd129FeQ8FBxUPBQcVj346TOdTJXesuZPnz5vH35z1Ka77l4t7/j7Q+6dKFMaj3x6N/FTJqCVaqDuoeCg4qHgoOIATcIbhUdm4I+JVEXFIROwy6fEj+m7TxqglWqg7qHgoOKh4KDiooFILiQSciDgZ+BLwQWBdRBzdtvnjfbfZdt/PeWwmJ1qoO6h4KDioeCg4qKBSC5UEnPcCB2TmUxGxCLg2IhZl5gUUa3JPSUSsAFYAxKz5jI3tvMNio5Zooe6g4qHgoOKh4KCCSi0kEnCAWZn5FEBmPgQsAd4SEefTpXFn5srMHM/M8V6aNoxeooW6g4qHgoOKh4KDCiq1UEnAeSwi9s/MNQDlkffbgM8C+/Xdpo1RS7RQd1DxUHBQ8VBwACfgDMOjKgFnb+DZzHxsim1/kJnfrtqBF5kyRh8vMqXHdBJwNnbZVtm0jTHG9B/Zz3EbY4yZGjduY4xpGG7cxhjTMGTXKjGDwRehjDIK81NlbjZyrRJjjDFT48ZtjDENw43bGGMahhu3McY0DDduY4xpGNKNe5SiiJrg4IgqPQ8FBxWPUZqfso17bGyMCy84m7cdtZz9Xnswy5YtZd99XzGSHgoOAEuPPIyLz//b2vfbjkotFDwUHJQ8Rml+bk8Czusj4sDy/qsj4q8i4si+m0xi1KKI1B3AEVVqHgoOSh6jND+rEnDOAC4E/jEiPgFcBOwCnBYRH+27TRujFkWk7qCCSi0UPBQclDwUqKsWVetxvx3YH5gLPAbsnZlPRsQnge8BZ0/1on4k4IxaFJG6gwoqtVDwUHBQ8lCgrlpUnSp5NjMnMvPXwP2Z+WQp8jSwudOL+pGAM2pRROoOKqjUQsFDwUHJQwGV6LJnIuL55f0DtjwYEfPp0rj7wahFEak7qKBSCwUPBQclDwVUosvemJm/AcjM9kY9G3h3323aGLUoInUHcESVmoeCg5LHKM1Prw44YiisvgY6K7AZLRTmp8rc9OqAxhgzg3DjNsaYhuHGbYwxDcPnuM3IonA+FTTOqboWevgctzHGzCDcuI0xpmG4cRtjTMNw4zbGmIbhxm2MMQ1DunErpGqoeCg4qHgoOIxS2koVrkX9HrKNWyVVQ8FDwUHFQ8EBRittpQrXon6PHW7cEXF53y2mQCVVQ8FDwUHFQ8EBRittpQrXon6PqgSc6yfdbgD+85av+27ThkqqhoKHgoOKh4KDCq5FC5VaqCTg7A1sAC4BEghgHDiv24ucgDPzHFQ8FBxUcC1aqNRCJQFnHPg+8FHgl5m5Cng6M7+Zmd/s9CIn4Mw8BxUPBQcVXIsWKrWQSMDJzM2Z+ffACcBHI+Iiqo/S+4JKqoaCh4KDioeCgwquRQuVWqgk4ACQmRuBYyPircCTfbeYApVUDQUPBQcVDwUHGK20lSpci/o9vDqgGVm8Il4L10IPrw5ojDEzCDduY4xpGG7cxhjTMAb+CRGVc2fGTEblfKrCe0SlFgoojEcVPuI2xpiG4cZtjDENw43bGGMahhu3McY0DDduY4xpGNKNWyFZQ8FBxUPBQclDIXHFtdByqGs8pBu3QrKGgoOKh4KDiodK4oproeMA9Y3HDjXuiHhDRPxVRBw+KKF2FJI1FBxUPBQcVDxUEldcCx0HqG88qhJwbm+7/17gImBX4IyIOG3AbsbIopK4ooBCLRQc6qTqiHt22/0VwGGZeSZwOHBcpxdFxIqIuCMi7rjk8qv6oGmMFiqJKwoo1ELBoU6q/uR9LCJ+i6LBR2b+H4DM/FVEPNvpRZm5ElgJsOnxB2Zu9czIopK4ooBCLRQc6qTqiHs+RXTZHcDuEfEigIjYhSJ/0piRRCVxRQGFWig41ElPQQoR8Xxgr8x8sOq50znibk/W2GP33YaSrKHgoOKh4NBPj+kurPSWI97EeeeduTXp5BPnXNjT95nOokYzrRYKDgrjATD7hS/reHA88AQcnyoxqqisiKewGp1KLRRQGA/o3rilP8dtjDHmubhxG2NMw3DjNsaYhuHGbYwxDWPg0WWmhcIFIJULL8aY3vERtzHGNAw3bmOMaRhu3MYY0zDcuI0xpmFIN26FdA8FBxitdI+meHhMWijUQsHBCThopHsoOIxaukcTPDwmLRRqoeAAIgk4EfG7EfGC8v68iDgzIm6IiHMjYv6g5RTSPRQcRi3dowkeHpMWCrVQcACRBBzgs8Cvy/sXUCzzem752KUD9DJtjFq6RxPwmLRQqIWCQ51UNe6xzNwSmDCemadm5rfKFJyXdXqRE3D6y6ilezQBj0kLhVooONRJ1V9OrouIEzLzUuCHETGemXdExCuBTZ1e5ASc/jJq6R5NwGPSQqEWCg51UnXE/RfAH0XE/cCrgdsi4gHgM+U2UwOjlu7RBDwmLRRqoeBQJ12PuDPzl8B7ImJXilMjOwEbM7OWH2XtaRKHLF0+9NSXYTlMTExwyqmnc+NXrtya7rFhw721OoBGLVQ8PCYtFGqh4AD1jYcTcGrEi0xpoTAeoDEmKrVQQGE8wAk4xhgzo3DjNsaYhuHGbYwxDcON2xhjGsbAL07uNGehL06WqFz0UMAXw4zpzrPPPOKLk8YYM1Nw4zbGmIbhxm2MMQ3DjdsYYxqGdONWSLRQ8VBIOlFwAI3xUPFQcFDxUHCoy0O2caskWqh4KCSdKDiojIeCh4KDioeCQ50eVQk4J0fEPn3f63agkmih4qGQdKLgoDIeCh4KDioeCg51elQdcZ8FfC8ibo2IkyJiz74bdEAl0ULFwxSojIeCh4KDioeCQ50eVY37AWBvigZ+ALAhIm6KiHeXS71OSXsCzubNv+pJTCXRQsXDFKiMh4KHgoOKh4JDnR5VjTszc3Nm3pyZJwILgE8DR1A09U4vWpmZ45k5Pja2c09iKokWKh6mQGU8FDwUHFQ8FBzq9Khq3Nv8+MjMTZl5fWb+GfCSvtu0oZJooeJhClTGQ8FDwUHFQ8GhTo+qzMllnTZk5tN9dtkGlUQLFQ+FpBMFB5XxUPBQcFDxUHCo08OLTNWIF5lq4UWmjOmOF5kyxpgZhBu3McY0DDduY4xpGG7cxhjTMKo+VTJtfEHOqOK52ULlYrHCmKjUohs+4jbGmIbhxm2MMQ3DjdsYYxqGG7cxxjQM6catkLii4KDioeAAGkknKrVQ8fCYtBjpBBzQSFxRcFDxUHBQSTpRqIWKh8ekhUoCzpyIeFdEHFp+/c6IuCgiPhARs/tuMwmFxBUFBxUPBQeVpBOFWqh4eExaqCTgXAq8FTglIq4AjgW+BxwIXNJ3G2MqUEk6MS08Ji1UEnD2y8xlwJ8AhwNvz8wrgBOA13V6UXsCziWXX9U/WzPyqCSdmBYekxZ11aLqLyfHImIOsDPwfGA+8HNgLtDxVElmrgRWAmx6/IHRHEEzEFSSTkwLj0kLlQScfwbuBtYAHwWuiYjPAKuBL/TdxpgKVJJOTAuPSYu6alEZpBARCwAy8ycRsRtwKPBwZt6+PTuYzhF3e+LKHrvvNvTUl2E5qHj002E660G85Yg3cd55Z25NGPnEORf29H2msy6Gwnj002O663PMpDFRqUW3IIWBJ+D4VImZCoWFfBQWNFJBYTxAY0xUauEEHGOMmUG4cRtjTMNw4zbGmIbhxm2MMQ1j4Ak4xqiichFKAYWLgmb78RG3McY0DDduY4xpGG7cxhjTMNy4jTGmYUg3boVECwUHFQ8FB9BIW1HxUHBQmRcqHk7AEUi0UHBQ8VBwUElbUfBQcACNeaHiIZGAM2wUEi0UHFQ8FBxU0lYUPBQcQGNeqHioJOAQES+PiL+OiAsi4ryIeH9EzO+7iTHbgUraioKHgoPZFokEnIg4GbgYeB5FXNk8YB/gtohY0uV1TsAxA0ElbUXBQ8HBbItKAs57gf0zcyIizgduzMwlEfFPwJfoEF/mBBwzKFTSVhQ8FBzMtqgk4ECruc8FdgXIzIfpEl1mzKBQSVtR8FBwMNtS15hUNe5LgNURsRK4DbgIICL2pMieHCgfOuMcjnvfX/LQwxs5ZOlyvnjD1wa9S0kHFQ8Fh4mJCU459XRu/MqVrFu7imuvvYENG+4dSQ8FB9CYFyoedY3J9kSXvQbYF1iXmXfv6A58qsRMhRd40sKLTLVQmZvdEnAqVwfMzPXA+r4aGWOM6Rnpz3EbY4x5Lm7cxhjTMNy4jTGmYQw8AUfhRL/KhReFWqigMiamwHOzRRPmpo+4jTGmYbhxG2NMw3DjNsaYhuHGbYwxDUO6cTvdo4VCLVQ8FMZEwUHJQ2FeKDjUNR6yjdvpHi1UaqHioTAmCg4qHgrzQsEB6hsP2cbtdI8WKrVQ8VAYEwUHFQ+FeaHgAPWNh2zjdrpHC5VaqHgYLRTmhYJDncg2bqd7tFCphYqH0UJhXig41ElVdNn8iDgnIu6OiJ+Vt7vKx3br8rqt0WWbN/+qJzGne7RQqYWKh9FCYV4oONRJ1RH31cAvgCWZuUdm7gEcXD52TacXZebKzBzPzPGxsZ17EnO6RwuVWqh4GC0U5oWCQ51UrVWyKDPPbX8gMx8Dzo2IPx+c1rZJErPGxrjsc/86tHSP1T9YyxNPPMkhS5dz0onHc0zNFz1UaqHioTAmCg4qHgrzQsEB6huPrgk4EXEz8D+Bz2XmT8vH9gLeAxyWmYdW7WCnOQuHfqJJZdEYL+TTQmVMTIHnZguVuTn7hS/rmIBTdapkGbAH8M2I+HlE/BxYBewOHNs3Q2OMMdtN11MlmfkL4CPlbRsi4gTg0gF5GWOM6cB0Pg54Zt8sjDHGbDddj7gjYm2nTcBe/dcxxhhTRdXFyZ8Cb6b4+N82m4DvZOaC575qWzY9/sDQL06aFioXoRQuAKnUwpipePaZRzpenKz6OOCXgV0yc83kDRGxappexhhjeqDq4uSJXba9s/86xhhjqpBdq8QYY8zUuHEbY0zDcOM2xpiGId24FWKZFByUPEYpHqoKhVooOKh4KDjU5SHduBVimRQcVDxGLR6qGwq1UHBQ8VBwqNNDunErxDIpOKh4jFo8VDcUaqHgoOKh4FCnh3TjNlqMWjxUNxRqoeCg4qHgUKdHz407Ir7aZdvWBJxLLr+q110YMUYtHqobCrVQcFDxUHCo06NqrZL/1GkTsH+n12XmSmAl+E/eZxKjFg/VDYVaKDioeCg41OlRdcS9GvgUcN6k26eAjpmTZmYyavFQ3VCohYKDioeCQ50eVWuV3AW8LzPvm7whIn7cd5tJKMQyKTioeIxaPFQ3FGqh4KDioeBQp0fV6oBvB+7MzHum2LY0M6+r2oFPlWihsiKeVwc0pjs9rw6Ymdd22fxbPRsZY4zpGSfgGGNMw3ACjjHGNIyqi5N70SUBZyBGMxifU23hWpip8LWP7cMJOMYY0zCcgGOMMQ3Da5UYY0zDcOM2xpiG4cZtjDENQ7pxKySdKDjAaKV7NMFBxUPBQcVjlN6r0o1bIelEwWHU0j3UHVQ8FByUPEbpvSrduBWSThQcRi3dQ91BxUPBQcljlN6r0o3bFIxauoe6g4qHgoOShwJ11aJqdcAXAP8N2Bv4amZe2bbt05l5UofXrQBWlF+uLIMVemLx4sWLJiYmvv2jH/1oYa/fY7oIOBxL8ResfxERKzLzaeD1wAeH4RERt5djevwQPFyLSQ64FltRea8OuhZVR9yXUvx5+xeBd0TEFyNibrnt9zq9KDNXZuZ4eeu5aW9hYmJi9+l+j4Y7bAT2Ke+voPhB+pPOTx+4x5YfysPwcC2e6wCuxVZE3qsDrUVV4355Zp6Wmddl5h8D/w58IyL26LeI6cpq4BXAS+fOnRvAO4Drh+WxePHiOcCcIXm4FpMccC2UqKUWVY17bkRsfU5mnk2RJXkLMPDmvXjx4quA22bPnj138eLFGxcvXtzxT/BnsgPwLPBfgK/dd999rwGuBtYPy+Omm256JUU60jA8XItJDrgWgNZ7deC1yMyON+DvgEOnePwI4L5ur+3nDVhR176UHVQ8FBxUPBQcVDwUHFQ8Bu3Q9eJkNyLihMy8tKcXG2OM6ZnpNO6HM/MlffYxxhhTgRNwjDGmYVRdnNwLeBdw1BS3nw1WrUVEDDxtJyJ2i4iTyvtLIuLLg97njjg1iYh4akDfd6ipSxFxckTcFRGfr2l/iyJiXR37qvCY1nsjIt4TEQsGY9dxn39T5/7a9juQuT+Zqsa9JQHnf0+6PQSsGrhdSWb+fg272Q1Qa5KKTkOjpnnQjZOAIzPzuKonRkRVutRA6fP+pzsP3wPU2riBoTTu2hj21dftvEL7VA37+ALwNLCG4rOYq4BrgbuBz9O6HnAA8E3g+8DXgBfX5PTJ8rYOuBNYNuB6XFf+H9dTXiEHngLOBn4IfBfYq3z8pcBtZd3OGtR4bfm+wJJO4zPAelwMPFPW/r+W9Vlb1uF3yud8jOLjsjcDV/Zhn4soPlL2mXIcbgbmAS8HbirH51bgVeXzLwPOB/4XcB6wM/DZclx+ABw94PfG/yi3ryvrEMDby3lzT/n6eYOeq8A5wES5v8/3eV8fBk4u7/898I3y/iHAv3R5j/wH4OvlnPk68JJpeQxysvexWHU07kXAuvL+EuCXFH/1NFY2pTcAsylCkvcsn7cM+GxNTscA/wbMojiF9TCD/aGxe/nvvPKNuAeQwFHl438HnF7evx54V3n/A4MaL7Zt3M8ZnxrmyEPAC4F/AM4oH3sTsKa8/7GygfSlOZXj/yywf/n11cDy8o3/ivKx321rHpdR/JY8q/z648Dy8v5uwL3AztOchx1rv2XOlPevaJsrq4DxmufqoObg7wHXlPdvBW4v+8IZwPu6vEduAN5d3v9z4LrpeHiRqc7cnpkbM3MzxU/uRcBi4D8C/xYRa4DTKSZwHbwBuCozJzLzpxRH/QcOcH8nR8SWo4Z9KP5C7xmKxgBFg1pU3v8D4Kry/hUDdGpnqvGpizdQ/j8z8xvAHhExv9x2fRZrhvSLB7MV1r2l5r8PXFPOwX8CXtz2/Gsyc6K8fzhwWvm8VcDzgH58EqxT7Q+OiO9FxJ0UP9Be04d9bQ9TzdVB8X3ggIjYFfgNxQ+uceAPKRp5p/fIQcCWtZ6uoJhDPTPU83Di/Kbt/gRFrQJYn5kHDcEnattRxBLgUOCgzPx1RKyieNNvyvKQgVZNttDb50p7Z6rxqYupxmLL//9Xfd7X5P/nXsATmbl/h+e37z+AYzLzngE77RQRzwM+TXFk/eOI+BjFnBkoXebqQMjMTRHxEHACxW/fa4GDKU5f3UX398g232o6Hj7ibvF/garFfO8B9oyIgwAiYnZEDPKoot3pFmBZRMyKiD2BN1L8mjYI5gO/KN8Ir6LLgmIl36ZYkwGg8sLdDOAWyv9n2Tgez8wna9r3k8CDEXFsuf+IiNd2eO7XgA9GRJTPfV2P+9ye98aWZvl4ROxCcW57R17fK53m6qaImD2gfd4C/HX5763A+ylOl3Vrxt9h2/fIt6Yj4MZdkpk/A75dfvzqkx2e8wzFhDy3/NVsDcWvrXU4HUTx0/2HwDeAD2fmYwPa9U0UR1FrKS42frfi+acAH4iI1RRvpJnOx4Dxsj7nAO+uef/HASeWc3A9cHSH551Fcf51bTmHzuplZ9v53niC4iLqnRQXC1e3bb4MuDgi1kTEvF4cutBprq6k+H8P4qObt1KcnrqtPG35/8rHunEycELpeTzFe6Znev7LSWOMMcPBR9zGGNMw3LiNMaZhuHEbY0zDcOM2xpiG4cZtjDENw43bGGMahhu3McY0jP8PxnzvlW36RoUAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import seaborn as sns\n",
    "sns.heatmap(X, annot=True, cbar=False, xticklabels=freq_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Лемматизация и стемминг текста\n",
    "\n",
    "Обычно тексты содержат разные грамматические формы одного и того же слова, а также могут встречаться однокоренные слова.\\\n",
    "Лемматизация и стемминг преследуют цель привести все встречающиеся словоформы к одной, нормальной словарной форме.\n",
    "\n",
    "Пример:\n",
    "\n",
    "* *dog, dogs, dog’s, dogs’ => dog*\n",
    "\n",
    "Лемматизация и стемминг – это частные случаи нормализации и они отличаются.\n",
    "\n",
    "**Стемминг** – это грубый эвристический процесс, который отрезает «лишнее» от корня слов, часто это приводит к потере словообразовательных суффиксов.\n",
    "\n",
    "**Лемматизация** – это более тонкий процесс, который использует словарь и морфологический анализ, чтобы в итоге привести слово к его канонической форме – лемме.\n",
    "\n",
    "Отличие в том, что стеммер (конкретная реализация алгоритма стемминга – прим.переводчика) действует без знания контекста и, соответственно, не понимает разницу между словами, которые имеют разный смысл в зависимости от части речи. Однако у стеммеров есть и свои преимущества: их проще внедрить и они работают быстрее. Плюс, более низкая «аккуратность» может не иметь значения в некоторых случаях.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He --> -PRON-\n",
      "was --> be\n",
      "running --> run\n",
      "late --> late\n",
      ". --> .\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"He was running late.\")\n",
    "for token in doc:\n",
    "    print('{} --> {}'.format(token, token.lemma_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "He --> He\n",
      "was --> wa\n",
      "running --> run\n",
      "late --> late\n",
      ". --> .\n"
     ]
    }
   ],
   "source": [
    "from nltk.stem.porter import PorterStemmer\n",
    "stemmer = PorterStemmer()\n",
    "for token in u\"He was running late .\".split():\n",
    "    print('{} --> {}'.format(token, stemmer.stem(token)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[1 1 0 1 0 1 1]\n",
      " [0 0 1 1 1 1 0]]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1a2fa50810>"
      ]
     },
     "execution_count": 231,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = ['Time flies flies like an arrow.', 'Fruit flies like a banana.']\n",
    "one_hot_vectorizer = CountVectorizer(binary=True)\n",
    "one_hot = one_hot_vectorizer.fit_transform(corpus).toarray()\n",
    "vocab = list(sorted(one_hot_vectorizer.vocabulary_.keys()))\n",
    "print(one_hot)\n",
    "sns.heatmap(one_hot, annot=True, cbar=False, xticklabels=vocab, yticklabels=['Sentence1 ','Sentence 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.axes._subplots.AxesSubplot at 0x1213770b8>"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "import seaborn as sns\n",
    "\n",
    "corpus = ['Time flies flies like an arrow.', 'Fruit flies like a banana.']\n",
    "tfidf_vectorizer = TfidfVectorizer()\n",
    "tfidf = tfidf_vectorizer.fit_transform(corpus).toarray()\n",
    "vocab = list(sorted(one_hot_vectorizer.vocabulary_.keys()))\n",
    "sns.heatmap(tfidf, annot=True, cbar=False, xticklabels=vocab, yticklabels=['Sentence 1', 'Sentence 2'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary#PROPN\n",
      "slapped#VERB\n",
      "the#DET\n",
      "green#ADJ\n",
      "witch#NOUN\n",
      ".#PUNCT\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp('Mary slapped the green witch.')\n",
    "for token in doc:\n",
    "    print('{}#{}'.format(token, token.pos_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 181,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mary#NP\n",
      "the green witch#NP\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "nlp = spacy.load('en_core_web_sm')\n",
    "doc = nlp(u\"Mary slapped the green witch.\")\n",
    "for chunk in doc.noun_chunks:\n",
    "    print ('{}#{}'.format(chunk, chunk.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Apple#ORG\n",
      "U.K.#GPE\n",
      "Billie Wang#PERSON\n",
      "$1 billion#MONEY\n"
     ]
    }
   ],
   "source": [
    "#entities\n",
    "# doc.ents is useful in problems of NER(Named entity recognition) \n",
    "#Check: https://en.wikipedia.org/wiki/Named-entity_recognition\n",
    "import spacy\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "doc = nlp(\"Apple  is looking at buying U.K. startup Billie Wang for $1 billion\")\n",
    "\n",
    "for ent in doc.ents:\n",
    "    print(\"{}#{}\".format(ent.text, ent.label_))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
